---
title: "Nyack_Floodplain_Flood_Finder"
author: "Amalia Handler"
date: "5/12/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

How to find a flood on a river

Potential things to try
- A threshold associated with the 1st derivative
- Use the anomalize package that was used to detect bad data

Questions/values to help get started
- What are typical 1st derivative values associated with a flood rising limb?
    - The geometric mean is 0.0092
    - The arithmetic mean is 0.0121
- What is the typical window of time used to consider a flood?
    - The rising limb varies between 24 and 60 hours
    - The windows considered so far are 200-400 hours or 8-16 days

```{r}
# The data
level <- read.csv('./Data/Nyack_level_cleaned.csv', header = TRUE, stringsAsFactors = FALSE)

# Remove questionable and bad data
level <- level[-which(level$level_m == -999 | level$level_m_flag == 1 | level$level_m_flag == 2),]

# Convert datetime to POSIX variable type
level$datetime <- as.POSIXct(level$datetime, tz = "MST")

# Rank groundwater wells by distance from the Middle Fork of the Flathead River
# The water level on the Middle Fork (CASC sensor) receives a rank of 1
sensor <- c(6,9,5,7,4,1,3)
rank   <- c(1:7)
rank   <- data.frame(sensor, rank)
level  <- merge(level, rank, by.x = "sensor_number", by.y = "sensor")

# Subset the water level data to only include the sensors for this analysis
level <- level[level$sensor_number %in% sensor,]

# Break the df into a list based on rank
level <- split(level, f = as.factor(level$rank))

# Make the names the sensor number
names(level) <- sensor

# Order each df by the datetime
level <- lapply(level, function(x){
  x[order(x$datetime),]
})

```

Start out by considering one year of data that has floods I've already identified (2014)

Calculate the 1st derivative for the whole time series for the main stem

Flag all instances where the 1st derivative exceeds the threshold (make it so the threshold is easily changable)

```{r}
library(signal)

# SUbset to 2014
lvl_14 <- level[[1]][level[[1]]$datetime >= as.POSIXct('2014-01-01') & level[[1]]$datetime <= as.POSIXct('2014-12-31'),]

# Savitsky-Golay filter settings
# p - order of polynomial line fit
# n - number of observations in the window (must be odd)
# m - derivative order to be returned of the fitted line
sg <- sgolay(p = 3, n = 17, m = 0)
sgd <- sgolay(p = 3, n = 17, m = 1)

# Calculate the 1st derivative of the main stem water level
m_derv <- filter(sgd, lvl_14$level_m)

# Set the threshold for flaggin
TH <- 0.0092

# Flag observations over the threshold
lvl_14$flood_flag <- 0
lvl_14$flood_flag[m_derv >= TH] <- 1

# Plot it out
par(mar = c(4,4,1,1))
plot(lvl_14$datetime, lvl_14$level_m, pch = 19, cex = 0.5)
points(lvl_14$datetime[m_derv >= TH], lvl_14$level_m[m_derv >= TH], pch = 19, cex = 0.5, col = 'blue')

# Plot a smaller time-chunk
lvl_14$derv <- m_derv
lvl_14$smooth <- filter(sg, lvl_14$level_m)
tmp <- lvl_14[lvl_14$datetime >= as.POSIXct('2014-02-25') & lvl_14$datetime <= as.POSIXct('2014-03-05'),]

par(mfrow = c(2,1), mar = c(2,2,1,1))
plot(tmp$datetime, tmp$level_m, pch = 19, cex = 0.5)
points(tmp$datetime[tmp$derv >= TH], tmp$level_m[tmp$derv >= TH], pch = 19, cex = 0.5, col = 'blue')
lines(tmp$datetime, tmp$smooth)

plot(tmp$datetime, tmp$derv, pch = 19, cex = 0.5)
points(tmp$datetime[tmp$derv >= TH], tmp$derv[tmp$derv >= TH], pch = 19, cex = 0.5, col = 'blue')

# Looks like an additional filter is needed to prevent a few observations from being flagged
# Also need a filter to remove the situations where observation around missing data are flagged. Work on this first.

tmp <- tmp[order(tmp$datetime),]

tmp$flag <- 0
tmp$flag[tmp$derv >= TH] <- 1

tmp[50:150,c('datetime','level_m','derv','flag')]

r <- rnorm(100)
r[50:55] <- NA
filter(sgd, r)


```

