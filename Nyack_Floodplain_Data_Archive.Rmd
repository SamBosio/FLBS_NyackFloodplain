---
title: "Nyack Floodplain Data Archiving"
author: "Amalia Handler"
date: "6/24/2019"
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

Code to compile and organize Nyack Floodplain data meterological and hydrologic data into an archivable format.

Approach to start
- Figure out the structure of each df for HA07. Determine what is duplicate data and if anything has changed

Load the data
```{r include = FALSE}
options(stringsAsFactors = FALSE)
library(tidyverse)

# Get the data
temp <- read.delim("./Data/CR1000_HA15_Table1.dat", 
                   sep = ",", skip = 4, header = FALSE)

# Add the column headers
colnames(temp) <- colnames(read.delim("./Data/CR1000_HA15_Table1.dat", 
                                      sep = ",", skip = 1, header = TRUE))

head(temp)

ha07_files <- list.files(path = "./Data/HA07")

ha07_water_files <- ha07_files[grepl("_Water", ha07_files)]

# Testing te function
file_name <- "CR1000_HA07_Water - thru6_7_2016.dat"

# Write a function to load in the water files
load_ha07_water_file <- function(file_name){
  # Read in the file
  temp <- read.delim(paste("./Data/HA07/", file_name, sep = ''), 
                     sep = ",", skip = 4, header = FALSE)
  
  colnames(temp) <- colnames(read.delim(paste("./Data/HA07/", file_name, sep = ''), 
                                        sep = ",", skip = 1, header = TRUE))
  
  # Find the min and max sample dates in the file
  # Convert the timestamp variable to posix time
  temp$TIMESTAMP <- as.POSIXct(temp$TIMESTAMP, format = "%Y-%m-%d %H:%M:%S") 
  
  # Find the max
  max_time <- format(max(na.omit(temp$TIMESTAMP)), "%Y_%m_%d")
  
  # Find the min
  min_time <- format(min(na.omit(temp$TIMESTAMP)), "%Y_%m_%d")
  
  # Create a new file name using the station number, min, and max datetime
  new_name <- paste("HA07", min_time, "to", max_time, sep = '_')
  
  # Write the file to the same location in rds format
  saveRDS(temp, paste("./Data/HA07/", new_name, sep = ''))

}

# Apply the read in function to the water files in the directory
for(file in ha07_water_files){
  load_ha07_water_file(file)
}


ha07_1 <- readRDS(paste("./Data/HA07/", "HA07_2012_05_15_to_2012_07_06", sep = ''))
ha07_2 <- readRDS(paste("./Data/HA07/", "HA07_2012_07_06_to_2012_11_24", sep = ''))
ha07_3 <- readRDS(paste("./Data/HA07/", "HA07_2012_07_06_to_2013_03_31", sep = ''))
ha07_4 <- readRDS(paste("./Data/HA07/", "HA07_2013_04_01_to_2016_06_07", sep = ''))
ha07_5 <- readRDS(paste("./Data/HA07/", "HA07_2013_04_01_to_2018_07_10", sep = ''))
ha07_6 <- readRDS(paste("./Data/HA07/", "HA07_2013_04_01_to_2018_07_16", sep = ''))
ha07_7 <- readRDS(paste("./Data/HA07/", "HA07_2013_04_01_to_2019_06_05", sep = ''))

nrow(HA07_1)
nrow(HA07_2)



# Identify the rows that have NA values in the timestamp column
temp %>%
       rowid_to_column() %>%
     filter(is.na(TIMESTAMP))

```


I need to figure out earliest date for each station and the variables in each dataframe.

```{r include = FALSE}
# List the files in the directory from Phil
ha07_files <- list.files(path = "./Data/HA07")

# Identify only those files related to water
ha07_water_files <- ha07_files[grepl("_Water", ha07_files)]

# Read in the files
toread <- paste("./Data/HA07/", ha07_water_files, sep = '')

ha07_water <- list()
ha07_water <- lapply(toread, read.delim, header = FALSE, sep = ',', skip = 4) 

# Get the column names
var_names <- list()
for(i in 1:length(ha07_water_files)){
  var_names[[i]] <- colnames(read.delim(paste("./Data/HA07/", ha07_water_files[i], sep = ''), sep = ",", skip = 1, header = TRUE))
}

# Add the column names to the list of files
ha07_water <- lapply(ha07_water, function(x) {
  colnames(x) <- var_names[[1]]
  x      
})

# Convert the timestamp to a datetime variable
ha07_water <- lapply(ha07_water, function(x){
 x$TIMESTAMP <- as.POSIXct(x$TIMESTAMP, format = "%Y-%m-%d %H:%M:%S")
 return(x)
})


# Find the max and min data in each file
max_min_date <- lapply(ha07_water, function(x){
  min_date <- format(as.Date(min(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  max_date <- format(as.Date(max(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  dates <- c(min_date, max_date)
  return(dates)
})

# Name the dataframes in the list
ha07_water_df_names <- sapply(max_min_date, function(x){
                              paste("ha07_water", x[1], "to", x[2], sep = '_')
})

names(ha07_water) <- ha07_water_df_names

# Earliest date of water data in these files
min_date <- NULL
max_date <- NULL
for(i in 1:length(max_min_date)){
  min_date[i] <- max_min_date[[i]][1]
  max_date[i] <- max_min_date[[i]][2]
}

min_date <- as.Date(min_date, format = "%Y_%m_%d")
max_date <- as.Date(max_date, format = "%Y_%m_%d")

min(min_date)
max(max_date)


```

Now read in the meterological data from HA07

```{r include = FALSE}
# List the files in the directory from Phil
ha07_files <- list.files(path = "./Data/HA07")

# Identify only those files related to water
ha07_met_files <- ha07_files[grepl("_Met", ha07_files)]

# Read in the files
toread <- paste("./Data/HA07/", ha07_met_files, sep = '')

ha07_met <- list()
ha07_met <- lapply(toread, read.delim, header = FALSE, sep = ',', skip = 4) 

# Get the column names
var_names <- list()
for(i in 1:length(ha07_met_files)){
  var_names[[i]] <- colnames(read.delim(paste("./Data/HA07/", ha07_met_files[i], sep = ''), sep = ",", skip = 1, header = TRUE))
}

# Apply the column names to the list of dfs
ha07_met <- lapply(ha07_met, function(x) {
  colnames(x) <- var_names[[1]]
  x      
})

# Convert the timestamp to a datetime variable
ha07_met <- lapply(ha07_met, function(x){
 x$TIMESTAMP <- as.POSIXct(x$TIMESTAMP, format = "%Y-%m-%d %H:%M:%S")
 return(x)
})


# Find the max and min data in each file
max_min_date <- lapply(ha07_met, function(x){
  min_date <- format(as.Date(min(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  max_date <- format(as.Date(max(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  dates <- c(min_date, max_date)
  return(dates)
})

# Name the dataframes in the list
ha07_met_df_names <- sapply(max_min_date, function(x){
                              paste("ha07_met", x[1], "to", x[2], sep = '_')
})

names(ha07_met) <- ha07_met_df_names

# Earliest date of water data in these files
min_date <- NULL
max_date <- NULL
for(i in 1:length(max_min_date)){
  min_date[i] <- max_min_date[[i]][1]
  max_date[i] <- max_min_date[[i]][2]
}

min_date <- as.Date(min_date, format = "%Y_%m_%d")
max_date <- as.Date(max_date, format = "%Y_%m_%d")

min(min_date)
max(max_date)

```


Now load in the data from Jeremy

```{r include = FALSE}
# List the files in the directory from Phil
ha_files_toread <- list.files(path = "./Data", pattern = ".dat")

# Read in the files
toread <- paste("./Data/", ha_files_toread, sep = '')

ha_files <- list()
ha_files <- lapply(toread, read.delim, header = FALSE, sep = ',', skip = 4) 

# Get the column names
var_names <- list()
for(i in 1:length(ha_files)){
  var_names[[i]] <- colnames(read.delim(paste("./Data/", ha_files_toread[i], sep = ''), sep = ",", skip = 1, header = TRUE))
}

# Apply the column names to the list of dfs
for(i in 1:length(var_names)){
  colnames(ha_files[[i]]) <- var_names[[i]]
}

# Convert the timestamp to a datetime variable
ha_files <- lapply(ha_files, function(x){
 x$TIMESTAMP <- as.POSIXct(x$TIMESTAMP, format = "%Y-%m-%d %H:%M:%S")
 return(x)
})

# Find the max and min data in each file and determine if it is a water data files or a meteorlogical file
file_info <- lapply(ha_files, function(x){
  if(colnames(x)[3] == "AirTC") {
    data_type <- "met"
  } else { data_type <- "water"
  }
  min_date <- format(as.Date(min(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  max_date <- format(as.Date(max(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  dates <- c(data_type, min_date, max_date)
  return(dates)
})

# Find the ha number for each file
# If the file contains "CR1000", then I can extract
# If the file name contains "Nyack" then need another method
well_info <- NULL
for(i in 1:length(ha_files_toread)){
  if(grepl("CR1000", ha_files_toread[i])){
  well_info[i] <- substr(ha_files_toread[i], 8, 11)
  } else {
    well_info[i] <- substr(ha_files_toread[i], 7, 10)
  }
}

# Name the dataframes in the list
ha_df_names <- sapply(max_min_date, function(x){
                              paste("ha07_met", x[1], "to", x[2], sep = '_')
  })

ha_df_names <- NULL
for(i in 1:length(well_info)){
  ha_df_names[i] <- paste(well_info[i], file_info[[i]][1], file_info[[i]][2], "to", file_info[[i]][3], sep = "_")
}

names(ha_files)  <- ha_df_names
names(var_names) <- ha_df_names

# Need to coerce the mutiple columns in the HA02 df from character to number. Seems that R does not see "NAN" is equivelent to "NaN".
column_numbers <- c(11, 14:17)
for(col in column_numbers){
  ha_files$HA02_water_2013_04_01_to_2019_06_23[,col] <- 
    as.numeric(ha_files$HA02_water_2013_04_01_to_2019_06_23[,col])
}

```


Jeremy sent a whole set of data that include data prior to 2013-04-01
Going through the metadata for each station, I found the start date for each station. This is the date at which it was confirmed that the station is collecting reliable data.

Station, start date
CASC, 2012-09-06
HA02, 2012-06-08
HA07, 2012-05-15 (met station and well)
HA08, 2011-12-14 (well)
HA08, 2012-05-02 (Beaver Creek)
HA10, 2011-12-16
HA12, 2012-04-26
HA15, 2012-04-26

# Append this older data to the longer contemporary datasets that Jeremy sent

```{r}

# Find all the initial data files with data between the start of monitoring and the start of the data from Jeremy (2013-04-01)
ini_files <- c(
  './Data/Nyack_RiverNET_HA02 Movie Rd/Nyack HA02 MovRd_Table1 5_8_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA07 MET/CR1000_HA07_Met_5_15_12 thru 7_6_12.dat',
  './Data/Nyack_RiverNET_HA07 MET/CR1000_HA07_Met 7_6_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA07 MET/CR1000_HA07_Water_5_15_12 thru 7_6_12.dat',
  './Data/Nyack_RiverNET_HA07 MET/CR1000_HA07_Water 7_6_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA08_Cabin/Manual download/Nyack HA08 Cabin_Table1 5_2_12 well only.dat',
  './Data/Nyack_RiverNET_HA08_Cabin/Manual download/Nyack HA08 Cabin_Table1 5_2_12 thru 11_28_12.dat',
  './Data/Nyack_RiverNET_HA08_Cabin/CR1000_HA08 Cabin_Table1 8_23_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA10_Sarg/CR1000_HA10_Table1 12_16_11 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA12_Methane/CR1000_HA12_Table1 4_26_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_HA15_Springhead/CR1000_HA15_Table1 4_26_12 thru 3_31_13.dat',
  './Data/Nyack_RiverNET_Cascadilla/Nyack CASC_Table1 9_6_12 thru 3_31_13.dat')

ini_ha_files <- lapply(ini_files, read.delim, header = FALSE, sep = ',', skip = 4) 

# Get the column names
var_names <- list()
for(i in 1:length(ini_ha_files)){
  var_names[[i]] <- colnames(read.delim(ini_files[i], sep = ",", skip = 1, header = TRUE))
}

# Apply the column names to the list of dfs
for(i in 1:length(var_names)){
  colnames(ini_ha_files[[i]]) <- var_names[[i]]
}

# Convert the timestamp to a datetime variable
ini_ha_files <- lapply(ini_ha_files, function(x){
 x$TIMESTAMP <- as.POSIXct(x$TIMESTAMP, format = "%Y-%m-%d %H:%M:%S")
 return(x)
})

# Apply names to the dataframes
names(ini_ha_files) <- c('ha02', 'ha07met', 'ha07met', 'ha07wtr', 'ha07wtr', 'ha08', 'ha08', 'ha08', 'ha10', 'ha12', 'ha15', 'casc')

# Coerce one of the column from one of the HA08 files from character to numeric
ini_ha_files[[6]]$DoConc2 <- as.numeric(ini_ha_files[[6]]$DoConc2)

# Bind together rows from the same station
ini_ha07met <- rbind(ini_ha_files[[2]], ini_ha_files[[3]])
ini_ha07wtr <- rbind(ini_ha_files[[4]], ini_ha_files[[5]])
ini_ha08    <- rbind(ini_ha_files[[6]], ini_ha_files[[7]], ini_ha_files[[8]])

# Remove duplicates from the above bound files
ini_ha07met <- ini_ha07met[!duplicated(ini_ha07met),]
ini_ha07wrt <- ini_ha07wtr[!duplicated(ini_ha07wtr),]
ini_ha08    <- ini_ha08[!duplicated(ini_ha08),]

# Make a new list, now with the bound, duplicates removed data
ini_ha_files <- list(ini_ha_files$casc, ini_ha_files$ha02, ini_ha07met, ini_ha07wtr, ini_ha08, ini_ha_files$ha10, ini_ha_files$ha12, ini_ha_files$ha15)

# Bind the initial data to the data from Jeremy

# First order the data
ha_files <- ha_files[order(names(ha_files))]

# Now bind together
ha_comb <- list()
for(i in 1:length(ha_files)){
  ha_comb[[i]] <- rbind(ini_ha_files[[i]], ha_files[[i]])
}

# Name the dfs
names(ha_comb) <- c('casc', 'ha02', 'ha07met', 'ha07wtr', 'ha08', 'ha10', 'ha12', 'ha15')

# Find the max and min data in each file and determine if it is a water data files or a meteorlogical file
file_info <- lapply(ha_comb, function(x){
  if(colnames(x)[3] == "AirTC") {
    data_type <- "met"
  } else { data_type <- "water"
  }
  min_date <- format(as.Date(min(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  max_date <- format(as.Date(max(na.omit(x$TIMESTAMP))), "%Y_%m_%d")
  dates <- c(data_type, min_date, max_date)
  return(dates)
})

```


Compile all water data into one df
Then separate into three spreadsheets for DO, Conductivity, and Water Level


```{r}

# For HA02, 08, and 15, there are two sets of sensors. Need to separate these into different dataframes
# HA02 has sensors 9 and 10
# HA08 has sensors 1 and 2
# HA15 has sensors 7 and 8
ha02_09 <- ha_comb$ha02[,colnames(ha_comb$ha02)[1:10]]
ha02_10 <- ha_comb$ha02[,colnames(ha_comb$ha02)[c(1,2,11:18)]]
ha08_01 <- ha_comb$ha08[,colnames(ha_comb$ha08)[1:10]]
ha08_02 <- ha_comb$ha08[,colnames(ha_comb$ha08)[c(1,2,11:18)]]
ha15_07 <- ha_comb$ha15[,colnames(ha_comb$ha15)[1:10]]
ha15_08 <- ha_comb$ha15[,colnames(ha_comb$ha15)[c(1,2,11:18)]]

### Stuck here. Trying to remove an erroneously created row with all NA values when subsetting to remove the test data from HA08_02. Problem is that other rows that have missing datetime information are removed in the process as well. Trying to figure out how to remove the test data without also removing the rows with NA values for the datetime AND without erroneously creating a new row with ALL NA values.

# HA08_02 didn't come online until 2012-05-02. Need to trim this df to only include dates greater than and including this date. From looking at the dataframe, it looks like the first numbers appear at 11:00:00.
ha08_02[is.na(ha08_02$TIMESTAMP),]

ha08_02 <- ha08_02[which(ha08_02$TIMESTAMP >= as.POSIXct('2012-05-02 11:00:00')),]

ha08_02[is.na(ha08_02$TIMESTAMP),]
# Remove the erroneously added first row populated with all NA values
ha08_02 <- ha08_02[2:nrow(ha08_02),]


# Recombine into a list
ha_sep <- list(ha_comb$casc, ha02_09, ha02_10, ha_comb$ha07wtr,
               ha08_01, ha08_02, ha_comb$ha10, ha_comb$ha12,
               ha15_07, ha15_08)

# Set the site and sensor numbers
site <- c('CASC', 'HA02', 'HA02', 'HA07', 'HA08', 'HA08', 'HA10', 'HA12', 'HA15', 'HA15')

sensor <- sapply(ha_sep, function(x){
  col_name <- colnames(x)[10]
  if(nchar(col_name) == 8){
    num <- substr(col_name, 8, 8)
    sensor_number <- paste('0', num, sep = '')
  } else {
    sensor_number <- substr(col_name, 8, 9)
  }
  return(sensor_number)
})


# Add columns to each df for the site and the sensor number
for(i in 1:length(ha_sep)){
  ha_sep[[i]]$site <- site[i]
  ha_sep[[i]]$sensor_number <- sensor[i]
}

# Now bind together all the files
# Need to rename all the columns first for compatabiility
# New column names
col_names <- c('datetime', 'record', 'do_conc', 'do_temp', 'do_sat', 'cond', 'ct', 'cond_temp', 'level_m', 'level_temp', 'site', 'sensor_number')

# Rename the columns for the dfs in the list
ha_rename <- lapply(ha_sep, function(x){
  colnames(x) <- col_names
  return(x)
})

# Bind together all rows
ha_all <- do.call("rbind", ha_rename)

# Check that the number of rows in ha_all is the sum of the rows from ha_rename
sum(sapply(ha_rename, nrow)) == nrow(ha_all)
# Perfecto!

# Rearrange the columns
ha_water <- ha_all[, c(11,12,1,3:10)]

# Save the new master file
saveRDS(ha_water, './Data/All_HA_Water_Data.rds')


```

What kind of NA values are in the df?

```{r}
# ha_water <- readRDS('./Data/All_HA_Water_Data')

# What timea are missing
temp <- subset(ha_water, is.na(ha_water$datetime))

# Can I just interpolate these values?
x <- 17
row_num <- as.numeric(row.names(temp[x,]))
ha_water[(row_num - 1):(row_num + 1), c('site','sensor_number','datetime')]
# Seems to be a pattern of the NA datetime values occuring around March 10, always at 02:00:00. 
# Find the dtime prior to the one missing
row_nums <- na.omit(as.numeric(row.names(temp)))

# How many of these NA's adhere to the above observed pattern?
test <- ha_water[(row_nums-1),]
# All instances for CASC, HA02, and HA07 were all instances where the dtime was missing around March 10, always at 02:00:00.

# All other instances?
# HA08
ha_water[(which(ha_water$site == "HA08" & is.na(ha_water$datetime)) + 1),]
# HA08 wells seem to be the same except for the last observation from HA08 for sensor 01
# Looked at the raw data file for HA08, but there is no oberservation after 2019-06-25 06:00:00. 

ha_water[(which(ha_water$site == "HA10" & is.na(ha_water$datetime)) - 1),]
ha_water[(which(ha_water$site == "HA10" & is.na(ha_water$datetime)) + 1),]

ha_water[(which(ha_water$site == "HA12" & is.na(ha_water$datetime)) - 1),]
ha_water[(which(ha_water$site == "HA12" & is.na(ha_water$datetime)) + 1),]

ha_water[(which(ha_water$site == "HA15" & is.na(ha_water$datetime)) - 1),]
ha_water[(which(ha_water$site == "HA15" & is.na(ha_water$datetime)) + 1),]





temp <- ha_water[which(is.na(ha_water)==TRUE),]

temp <- subset(ha_water, is.na(ha_water$datetime))

# Is there any pattern to the NA values

na.rows <- which(is.na(ha_water))

x <- 1
ha_water[(na.rows[x] - 10):(na.rows[x] +10),]

```



Visualize the 2013-present data

Explore the continuity in the data by plotting the whole record

Dissolved oxygen data

```{r}

# If I want to use the markdown capabilities
# echo = FALSE, fig.width = 4, fig.height = 3, res = 300, fig.cap = "DO concentration by well."

# To compile the water data from each site, exclude the meterological data
x <- ha_files[2:8]

png("./Figures/HA_DO_Conc.png", units = "in", 
    width = 12, height = 12, res = 300, bg = "transparent")

par(mfrow = c(5,2), oma = c(2,2,1,1), mar = c(3,5,2,0))

lapply(seq_along(x), function(i){
  if(ncol(x[[i]]) == 10) {
  plot(x[[i]][,1], x[[i]][,3], xlab = " ", ylab = "DO (mg/L)", 
       cex.lab = 2, cex.axis = 2)
  title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[3], sep = ' '), 
        line = 0.5, cex.main = 2)
  box(lwd = 2)
  } else {
       plot(x[[i]][,1], x[[i]][,3], xlab = " ", ylab = "DO (mg/L)", 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[3], sep = ' '), 
             line = 0.5, cex.main = 2)
       box(lwd = 2)
      
       plot(x[[i]][,1], x[[i]][,11], xlab = " ", ylab = "DO (mg/L)", 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[11], sep = ' '), 
       line = 0.5, cex.main = 2)
       box(lwd = 2)
  }
})

dev.off()
```


Conductivity Data

```{r}
# x <- ha_files[2:8]

y_label   <- "Cond (mS/cm)"
first_col <- 6
sec_col   <- 14

png("./Figures/HA_Cond.png", units = "in", 
    width = 12, height = 12, res = 300, bg = "transparent")

par(mfrow = c(5,2), oma = c(2,2,1,1), mar = c(3,5,2,0))

lapply(seq_along(x), function(i){
  if(ncol(x[[i]]) == 10) {
  plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
  title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '), 
        line = 0.5, cex.main = 2)
  box(lwd = 2)
  } else {
       plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '),
             line = 0.5, cex.main = 2)
       box(lwd = 2)
      
       plot(x[[i]][,1], x[[i]][,sec_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[sec_col], sep = ' '), 
       line = 0.5, cex.main = 2)
       box(lwd = 2)
  }
})

dev.off()

```


Water level

```{r}
# x <- ha_files[2:8]

y_label   <- "Water Level (m)"
first_col <- 9
sec_col   <- 17

png("./Figures/HA_WaterLevel.png", units = "in", 
    width = 12, height = 12, res = 300, bg = "transparent")

par(mfrow = c(5,2), oma = c(2,2,1,1), mar = c(3,5,2,0))

lapply(seq_along(x), function(i){
  if(ncol(x[[i]]) == 10) {
  plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
  title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '), 
        line = 0.5, cex.main = 2)
  box(lwd = 2)
  } else {
       plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '),
             line = 0.5, cex.main = 2)
       box(lwd = 2)
      
       plot(x[[i]][,1], x[[i]][,sec_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2)
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[sec_col], sep = ' '), 
       line = 0.5, cex.main = 2)
       box(lwd = 2)
  }
})

dev.off()

```


Temperature associated with the DO sensor

```{r}
# x <- ha_files[2:8]

y_label   <- "Temp (C)"
first_col <- 5
sec_col   <- 13

png("./Figures/HA_DO_Temp_ylim20.png", units = "in", 
    width = 12, height = 12, res = 300, bg = "transparent")

par(mfrow = c(5,2), oma = c(2,2,1,1), mar = c(3,5,2,0))

lapply(seq_along(x), function(i){
  if(ncol(x[[i]]) == 10) {
  plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2, ylim = c(0,20))
  title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '), 
        line = 0.5, cex.main = 2)
  box(lwd = 2)
  } else {
       plot(x[[i]][,1], x[[i]][,first_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2, ylim = c(0,20))
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[first_col], sep = ' '),
             line = 0.5, cex.main = 2)
       box(lwd = 2)
      
       plot(x[[i]][,1], x[[i]][,sec_col], xlab = " ", ylab = y_label, 
       cex.lab = 2, cex.axis = 2, ylim = c(0,20))
       title(paste(substr(names(x)[[i]], 1, 4), colnames(x[[i]])[sec_col], sep = ' '), 
       line = 0.5, cex.main = 2)
       box(lwd = 2)
  }
})

dev.off()

```

